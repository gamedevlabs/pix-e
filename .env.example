# OpenAI (Cloud LLM Provider)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_ORGANIZATION=org-your-organization-id  # Optional
LLM_ORCHESTRATOR_OPENAI_TIMEOUT_SECONDS=60

# Gemini (Cloud LLM Provider)
GEMINI_API_KEY=your-gemini-api-key-here
LLM_ORCHESTRATOR_GEMINI_TIMEOUT_SECONDS=60

# Logfire Configuration
# Required for capturing LLM prompts and completions in Gemini instrumentation
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true

# Project name for Logfire
LOGFIRE_PROJECT_NAME=*put your personal project name here*

# Ollama (Local LLM Provider)
LLM_ORCHESTRATOR_OLLAMA_BASE_URL=http://localhost:XXXXX
LLM_ORCHESTRATOR_OLLAMA_TIMEOUT_SECONDS=60

# Default timeout for operations (in milliseconds)
LLM_ORCHESTRATOR_DEFAULT_TIMEOUT_MS=120000

LLM_ORCHESTRATOR_MAX_PARALLEL_AGENTS=10

LLM_ORCHESTRATOR_DEFAULT_MODEL_PREFERENCE=auto

LLM_ORCHESTRATOR_DEFAULT_EXECUTION_MODE=agentic

LLM_ORCHESTRATOR_ARTIFACT_STORAGE_PATH=./artifacts

LLM_ORCHESTRATOR_MAX_ARTIFACT_SIZE_BYTES=10485760

LLM_ORCHESTRATOR_ARTIFACT_RETENTION_DAYS=30

LLM_ORCHESTRATOR_CACHE_TTL_SECONDS=3600

LLM_ORCHESTRATOR_CACHE_ENABLED=true

LLM_ORCHESTRATOR_CACHE_MAX_SIZE_MB=100

LLM_ORCHESTRATOR_RATE_LIMIT_PER_MINUTE=60

LLM_ORCHESTRATOR_MAX_CONCURRENT_RUNS=5

LLM_ORCHESTRATOR_MAX_REQUEST_SIZE_BYTES=1048576

LLM_ORCHESTRATOR_MAX_RESPONSE_SIZE_BYTES=10485760

LLM_ORCHESTRATOR_STREAMING_ENABLED=false

LLM_ORCHESTRATOR_ASYNC_EXECUTION_ENABLED=true

LLM_ORCHESTRATOR_DEBUG_LOGGING=false

LLM_ORCHESTRATOR_METRICS_ENABLED=false

LLM_ORCHESTRATOR_REQUIRE_AUTHENTICATION=true

LLM_ORCHESTRATOR_ALLOW_CORS=false

LLM_ORCHESTRATOR_CORS_ALLOWED_ORIGINS=http://localhost:3000